import streamlit as st
import pandas as pd
import random
import re
import gspread
from google.oauth2.service_account import Credentials

# ====== Google Sheets è¨­å®š ======
IMAGE_SHEET_ID = "1KUxQDhhnYS6tj4pFYAHwq9SzWxx3iDotTGXSzFUTU-s"
LOG_SHEET_ID = "1yQuifGNG8e77ka5HlJariXxgqPffrIviDZKgmS9FGCg"
scope = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
credentials = Credentials.from_service_account_info(st.secrets["gcp_service_account"], scopes=scope)
gc = gspread.authorize(credentials)
image_sheet = gc.open_by_key(IMAGE_SHEET_ID)
log_sheet = gc.open_by_key(LOG_SHEET_ID)


# ====== å¿…é ˆåˆ—ã®å®šç¾© ======
required_cols = ["å›ç­”è€…", "è¦ªãƒ•ã‚©ãƒ«ãƒ€", "æ™‚é–“", "é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å", "â‘ æœªèåˆ", "â‘¡æ¥è§¦", "â‘¢èåˆä¸­", "â‘£å®Œå…¨èåˆ"]
skip_cols = ["å›ç­”è€…", "è¦ªãƒ•ã‚©ãƒ«ãƒ€", "æ™‚é–“", "é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å", "ã‚¹ã‚­ãƒƒãƒ—ç†ç”±"]



@st.cache_data(ttl=60)
def load_ws_data(sheet_id: str, ws_name: str, header_cols: list) -> pd.DataFrame:
    gc = gspread.authorize(credentials)
    sheet = gc.open_by_key(sheet_id)
    try:
        ws = sheet.worksheet(ws_name)
        return pd.DataFrame(ws.get_all_records())
    except gspread.exceptions.WorksheetNotFound:
        sheet.add_worksheet(title=ws_name, rows="1000", cols=str(len(header_cols)))
        ws = sheet.worksheet(ws_name)
        ws.append_row(header_cols)
        return pd.DataFrame(columns=header_cols)

def df_to_sheet_to(sheet_obj, df, ws_name):
    ws = sheet_obj.worksheet(ws_name)
    ws.clear()
    if not df.empty:
        ws.update([df.columns.tolist()] + df.values.tolist())


# ====== ãƒ­ã‚°ã‚¤ãƒ³èªè¨¼ ======
USER_CREDENTIALS = {
    "mamiya": "a",
    "arai": "a",
    "yamazaki": "protoplast"
}

st.set_page_config(page_title="èåˆåº¦è©•ä¾¡", layout="centered")
st.title("èåˆåº¦è©•ä¾¡ - ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚«ãƒ¼ãƒ‰")

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.subheader("ãƒ­ã‚°ã‚¤ãƒ³")
    input_username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    input_password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if input_username in USER_CREDENTIALS and USER_CREDENTIALS[input_username] == input_password:
            st.session_state.authenticated = True
            st.session_state.username = re.sub(r'[^a-zA-Z0-9_ä¸€-é¾¯ã-ã‚“ã‚¡-ãƒ¶]', '_', input_username.strip())
            st.success("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
            st.rerun()
        else:
            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    st.stop()

# ====== è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å–å¾— ======
username = st.session_state.username
st.sidebar.markdown(f"**ãƒ­ã‚°ã‚¤ãƒ³ä¸­:** `{username}`")
combined_df = load_ws_data(LOG_SHEET_ID, "ä»Šå›ã®è©•ä¾¡", required_cols)
existing_df = combined_df.copy()
skip_df = load_ws_data(LOG_SHEET_ID, "ã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚°", skip_cols)
if "é¸æŠãƒ•ã‚©ãƒ«ãƒ€" in skip_df.columns:
    skip_df = skip_df[~skip_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"].str.contains("_SKIPPED_IMAGES", na=False)]
image_list_df = load_ws_data(IMAGE_SHEET_ID, "ç”»åƒãƒªã‚¹ãƒˆ", ["ãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å", "ç”»åƒURL"])



folder_names = sorted(image_list_df["ãƒ•ã‚©ãƒ«ãƒ€"].unique().tolist())

# === è©•ä¾¡æ¸ˆã¿ãƒ»ã‚¹ã‚­ãƒƒãƒ—æ¸ˆã¿ç”»åƒã®çµ„ã¿åˆã‚ã›å–å¾— ===
answered_pairs = set(zip(combined_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"], combined_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
if "é¸æŠãƒ•ã‚©ãƒ«ãƒ€" in skip_df.columns and "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å" in skip_df.columns:
    skipped_pairs = set(zip(skip_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"], skip_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
else:
    skipped_pairs = set()
done_pairs = answered_pairs.union(skipped_pairs)


# === ãƒ•ã‚©ãƒ«ãƒ€ã”ã¨ã®æœªè©•ä¾¡ç”»åƒãŒå­˜åœ¨ã™ã‚‹ã‹åˆ¤å®šã—ã¦ã€å®Œäº†ãƒ•ã‚©ãƒ«ãƒ€ã‚’é™¤å¤– ===
remaining_folders = []
for folder in folder_names:
    folder_df = image_list_df[image_list_df["ãƒ•ã‚©ãƒ«ãƒ€"] == folder]
    all_images = set(zip(folder_df["ãƒ•ã‚©ãƒ«ãƒ€"], folder_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
    if not all_images.issubset(done_pairs):
        remaining_folders.append(folder)


if not remaining_folders:
    st.success("ã™ã¹ã¦ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’è©•ä¾¡ã—ã¾ã—ãŸï¼")
    st.stop()

selected_folder = random.choice(remaining_folders)

if st.sidebar.button("é€”ä¸­ä¿å­˜"):
    if "buffered_entries" in st.session_state and st.session_state.buffered_entries:
        buffered_df = pd.DataFrame(st.session_state.buffered_entries)
        combined_df = pd.concat([existing_df, buffered_df], ignore_index=True)
        combined_df.drop_duplicates(subset=["å›ç­”è€…", "é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"], keep="last", inplace=True)

        summary = combined_df.groupby(["é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "æ™‚é–“"])[["â‘ æœªèåˆ", "â‘¡æ¥è§¦", "â‘¢èåˆä¸­", "â‘£å®Œå…¨èåˆ"]].sum().reset_index()
        summary.insert(0, "ä¸€æ„ID", summary["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"] + "_" + summary["æ™‚é–“"])

        # è©•ä¾¡ä¿å­˜å‰
        st.sidebar.markdown("ğŸ’¾ ä¿å­˜ç›´å‰ã®combined_df ä»¶æ•°: " + str(len(combined_df)))
        st.sidebar.markdown("ğŸ” ç¾åœ¨ã® combined_df ä»¶æ•°: " + str(len(combined_df)))
        st.sidebar.markdown("ğŸ“„ æœ€æ–°ã® combined_df ã®ä¸€éƒ¨:")
        st.sidebar.dataframe(combined_df.tail(5))

        
        df_to_sheet_to(log_sheet, combined_df, "ä»Šå›ã®è©•ä¾¡")
        df_to_sheet_to(log_sheet, summary, "åˆ†é¡åˆ¥ä»¶æ•°")
        df_to_sheet_to(log_sheet, skip_df, "ã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚°")

        st.session_state.buffered_entries = []
        st.sidebar.success("ä¸€æ™‚ä¿å­˜ã—ã¾ã—ãŸ")

folder_images = image_list_df[image_list_df["ãƒ•ã‚©ãƒ«ãƒ€"] == selected_folder]



if folder_images.empty:
    st.error("ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ã¯ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“")
    st.stop()

parent_folder_name = "mix"

# ====== å›ç­”ãƒ»ã‚¹ã‚­ãƒƒãƒ—æ¸ˆã¿ã®é‡è¤‡é™¤å¤– ======
user_df = combined_df[combined_df["å›ç­”è€…"] == username].copy()

st.sidebar.markdown(f"ğŸ‘¤ ãƒ•ã‚£ãƒ«ã‚¿å¾Œ user_df ä»¶æ•°: {len(user_df)}")
st.sidebar.markdown(f"ğŸ§ª ç¾åœ¨ã® username: `{username}`")


# skip_dfã«å¿…è¦ãªåˆ—ãŒã‚ã‚‹å ´åˆã ã‘å‡¦ç†ã™ã‚‹
if "é¸æŠãƒ•ã‚©ãƒ«ãƒ€" in skip_df.columns and "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å" in skip_df.columns:
    skip_pairs = set(zip(skip_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"], skip_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
else:
    skip_pairs = set()

# combined_dfã«ã¯å¸¸ã«ã‚ã‚‹å‰æï¼ˆãªã‘ã‚Œã°åŒæ§˜ã«ãƒã‚§ãƒƒã‚¯è¿½åŠ ãŒå¿…è¦ï¼‰
answered_pairs = set(zip(user_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"], user_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
all_done = answered_pairs.union(skip_pairs)


# ====== ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ======
if "image_files" not in st.session_state:
    folder_images["pair"] = list(zip(folder_images["ãƒ•ã‚©ãƒ«ãƒ€"], folder_images["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
    filtered_images = folder_images[~folder_images["pair"].isin(all_done)].drop(columns=["pair"])
    st.session_state.image_files = filtered_images.reset_index(drop=True)
    st.session_state.index = 0

if st.session_state.index >= len(st.session_state.image_files):
    st.success("ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã®ã™ã¹ã¦ã®ç”»åƒã‚’è©•ä¾¡ã—ã¾ã—ãŸ")

    # è©•ä¾¡çµæœã‚’ä¿å­˜
    if "buffered_entries" in st.session_state and st.session_state.buffered_entries:
        buffered_df = pd.DataFrame(st.session_state.buffered_entries)
        combined_df = pd.concat([existing_df, buffered_df], ignore_index=True)
        combined_df.drop_duplicates(subset=["å›ç­”è€…", "é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"], keep="last", inplace=True)

        summary = combined_df.groupby(["é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "æ™‚é–“"])[["â‘ æœªèåˆ", "â‘¡æ¥è§¦", "â‘¢èåˆä¸­", "â‘£å®Œå…¨èåˆ"]].sum().reset_index()
        summary.insert(0, "ä¸€æ„ID", summary["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"] + "_" + summary["æ™‚é–“"])

        df_to_sheet_to(log_sheet, combined_df, "ä»Šå›ã®è©•ä¾¡")
        df_to_sheet_to(log_sheet, summary, "åˆ†é¡åˆ¥ä»¶æ•°")
        df_to_sheet_to(log_sheet, skip_df, "ã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚°")

        existing_df = combined_df.copy()
        
        st.sidebar.markdown(f"ğŸ“¥ èª­ã¿è¾¼ã¿ç›´å¾Œã® existing_df ä»¶æ•°: {len(existing_df)}")

        st.session_state.buffered_entries = []
        st.sidebar.success("ä¿å­˜ã—ã¾ã—ãŸï¼ˆãƒ•ã‚©ãƒ«ãƒ€çµ‚äº†æ™‚ï¼‰")

    # --- æ¬¡ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸ã¶ ---
    answered_pairs = set(zip(combined_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"], combined_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
    if "é¸æŠãƒ•ã‚©ãƒ«ãƒ€" in skip_df.columns and "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å" in skip_df.columns:
        skipped_pairs = set(zip(skip_df["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"], skip_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
    else:
        skipped_pairs = set()
    done_pairs = answered_pairs.union(skipped_pairs)

    # ãƒ•ã‚©ãƒ«ãƒ€ã®å†é¸æŠ
    remaining_folders = []
    for folder in folder_names:
        folder_df = image_list_df[image_list_df["ãƒ•ã‚©ãƒ«ãƒ€"] == folder]
        all_images = set(zip(folder_df["ãƒ•ã‚©ãƒ«ãƒ€"], folder_df["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
        if not all_images.issubset(done_pairs):
            remaining_folders.append(folder)

    if not remaining_folders:
        st.success("ã™ã¹ã¦ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’è©•ä¾¡ã—ã¾ã—ãŸï¼")
        st.stop()

    # ãƒ•ã‚©ãƒ«ãƒ€ã¨ç”»åƒã‚’å†åˆæœŸåŒ–
    selected_folder = random.choice(remaining_folders)
    folder_images = image_list_df[image_list_df["ãƒ•ã‚©ãƒ«ãƒ€"] == selected_folder]
    all_done = answered_pairs.union(skipped_pairs)
    folder_images["pair"] = list(zip(folder_images["ãƒ•ã‚©ãƒ«ãƒ€"], folder_images["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]))
    filtered_images = folder_images[~folder_images["pair"].isin(all_done)].drop(columns=["pair"])
    st.session_state.image_files = filtered_images.reset_index(drop=True)
    st.session_state.index = 0
    st.rerun()

# ====== ç¾åœ¨ã®ç”»åƒè¡¨ç¤º ======
row = st.session_state.image_files.iloc[st.session_state.index]
current_file = row["ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"]
current_url = row["ç”»åƒURL"]

st.progress((st.session_state.index + 1) / len(st.session_state.image_files))
st.image(current_url, use_container_width=True)

# ====== åˆ†é¡å…¥åŠ› ======
st.markdown("### å„åˆ†é¡ã®å€‹æ•°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
col1, col2, col3, col4 = st.columns(4)
with col1:
    val_1 = st.number_input("â‘ æœªèåˆ", min_value=0, max_value=1000, step=1, key=f"val1_{current_file}")
with col2:
    val_2 = st.number_input("â‘¡æ¥è§¦", min_value=0, max_value=1000, step=1, key=f"val2_{current_file}")
with col3:
    val_3 = st.number_input("â‘¢èåˆä¸­", min_value=0, max_value=1000, step=1, key=f"val3_{current_file}")
with col4:
    val_4 = st.number_input("â‘£å®Œå…¨èåˆ", min_value=0, max_value=1000, step=1, key=f"val4_{current_file}")

col1, col2, col3 = st.columns(3)
with col1:
    if st.button("â† æˆ»ã‚‹"):
        if st.session_state.index > 0:
            st.session_state.index -= 1
            st.rerun()

with col2:
    if st.button("ã‚¹ã‚­ãƒƒãƒ—"):
        match = re.search(r'(\d+min)', selected_folder)
        time_str = match.group(1) if match else "ä¸æ˜"
        skip_entry = {
            "å›ç­”è€…": username,
            "è¦ªãƒ•ã‚©ãƒ«ãƒ€": parent_folder_name,
            "æ™‚é–“": time_str,
            "é¸æŠãƒ•ã‚©ãƒ«ãƒ€": selected_folder,
            "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å": current_file,
            "ã‚¹ã‚­ãƒƒãƒ—ç†ç”±": "åˆ¤åˆ¥ä¸èƒ½"
        }
        skip_df = pd.concat([skip_df, pd.DataFrame([skip_entry])], ignore_index=True)
        skip_df.drop_duplicates(subset=["å›ç­”è€…", "é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"], keep="last", inplace=True)

        st.session_state.index += 1
        st.rerun()

with col3:
    if st.button("é€²ã‚€ â†’"):
        total = val_1 + val_2 + val_3 + val_4
        if total == 0:
            st.warning("å°‘ãªãã¨ã‚‚1ã¤ã¯åˆ†é¡ã—ã¦ãã ã•ã„")
        else:
            match = re.search(r'(\d+min)', selected_folder)
            time_str = match.group(1) if match else "ä¸æ˜"
            new_entry = {
                "å›ç­”è€…": username,
                "è¦ªãƒ•ã‚©ãƒ«ãƒ€": parent_folder_name,
                "æ™‚é–“": time_str,
                "é¸æŠãƒ•ã‚©ãƒ«ãƒ€": selected_folder,
                "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å": current_file,
                "â‘ æœªèåˆ": val_1,
                "â‘¡æ¥è§¦": val_2,
                "â‘¢èåˆä¸­": val_3,
                "â‘£å®Œå…¨èåˆ": val_4
            }

            if "buffered_entries" not in st.session_state:
                st.session_state.buffered_entries = []
            st.session_state.buffered_entries.append(new_entry)

            if len(st.session_state.buffered_entries) >= 5:
                buffered_df = pd.DataFrame(st.session_state.buffered_entries)
                combined_df = pd.concat([existing_df, buffered_df], ignore_index=True)
                combined_df.drop_duplicates(subset=["å›ç­”è€…", "é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å"], keep="last", inplace=True)

                summary = combined_df.groupby(["é¸æŠãƒ•ã‚©ãƒ«ãƒ€", "æ™‚é–“"])[["â‘ æœªèåˆ", "â‘¡æ¥è§¦", "â‘¢èåˆä¸­", "â‘£å®Œå…¨èåˆ"]].sum().reset_index()
                summary.insert(0, "ä¸€æ„ID", summary["é¸æŠãƒ•ã‚©ãƒ«ãƒ€"] + "_" + summary["æ™‚é–“"])

                df_to_sheet_to(log_sheet, combined_df, "ä»Šå›ã®è©•ä¾¡")
                df_to_sheet_to(log_sheet, summary, "åˆ†é¡åˆ¥ä»¶æ•°")
                df_to_sheet_to(log_sheet, skip_df, "ã‚¹ã‚­ãƒƒãƒ—ãƒ­ã‚°")


                existing_df = combined_df.copy()
                st.session_state.buffered_entries = []

            st.session_state.index += 1
            st.rerun()
